from dotenv import load_dotenv
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from ollama import Client
from langchain.schema import Document
import re

# üîπ Carregar vari√°veis de ambiente
load_dotenv()

# üîπ Configurar o cliente Ollama
client = Client(host="http://localhost:11434")
model = "llama3.2"


def extrair_metadados(texto):
    padrao = re.compile(r"(Cap√≠tulo \d+): (.*?)\n(Parte \d+): (.*?)\n(.*?)(?=(\nCap√≠tulo \d+:|\Z))", re.DOTALL)
    
    capitulos = {}
    for correspondencia in padrao.finditer(texto):
        capitulo = correspondencia.group(1)
        parte = correspondencia.group(3)
        texto_parte = correspondencia.group(5).strip()
        
        if capitulo not in capitulos:
            capitulos[capitulo] = []
        
        capitulos[capitulo].append({"Parte": parte, "Texto": texto_parte})
    
    return capitulos

def processar_arquivo(caminho_arquivo):
    with open(caminho_arquivo, 'r', encoding='utf-8') as arquivo:
        texto = arquivo.read()
    return extrair_metadados(texto)

def criar_documentos(caminho_arquivo):
    capitulos = processar_arquivo(caminho_arquivo)
    documentos = []
    
    for capitulo, partes in capitulos.items():
        texto_completo = "\n".join([f"{parte['Parte']}: {parte['Texto']}" for parte in partes])
        documentos.append(Document(page_content=texto_completo, metadata={"Cap√≠tulo": capitulo}))
    
    return documentos

# Exemplo de uso
caminho_arquivo = "historia.txt"  # Substitua pelo caminho do seu arquivo
documentos = criar_documentos(caminho_arquivo)

# üîπ Criar o banco de vetores FAISS com metadados
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = FAISS.from_documents(documentos, embedding_model)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

# üîπ Hist√≥rico da conversa
historico_conversa = []

# üîπ Template para manter contexto
rag_template = """
Voc√™ √© um mestre de RPG de mesa tipo D&D conduzindo uma aventura,
Continue a hist√≥ria sem sair do contexto original,
Responda apenas com uma √∫nica frase sem oferecer op√ß√µes,
Em alguns momentos voce pode fazer alguns paragrafos para ficar mais dinamico e criativo,
Siga a narrativa, evite respostas longas e mantenha a continuidade l√≥gica dos eventos,
Nunca saia do contexto da hist√≥ria,
Sempre termine a frase perguntando algo para o jogador,
Responda apenas com uma √∫nica frase sem oferecer op√ß√µes sem que posivel,
Deixe o jogador poder fazer as atividades que qerer dentro desse universo, mesmo que nao for a historia principal, seje criativa,
Responda com uma pergunta no final referente a proxima A√ß√£o do jogador.

Capitulo Atual: {capitulo_atualtxt}

Parte Atual: {parte_atualtxt}

Contexto da hist√≥ria: {context}

√öltimas a√ß√µes do jogador: {historico}

A√ß√£o do jogador agora: {questao}
"""

prompt = ChatPromptTemplate.from_template(rag_template)

progresso_historia = {'capitulo_atual': 0, 'parte_atual': 0}

# Fun√ß√£o para avan√ßar na hist√≥ria
def avancar_historia(): 
    global progresso_historia

    # Verifica se o cap√≠tulo atual √© v√°lido
    if progresso_historia['capitulo_atual'] >= len(documentos):
        print("Hist√≥ria conclu√≠da!")
        return  # Retorna se a hist√≥ria estiver conclu√≠da

    # Verifica se a parte atual √© v√°lida para o cap√≠tulo atual
    if progresso_historia['parte_atual'] >= len(documentos[progresso_historia['capitulo_atual']]['partes']):
        # Se n√£o for v√°lida, reinicia a parte e avan√ßa para o pr√≥ximo cap√≠tulo
        progresso_historia['capitulo_atual'] += 1
        progresso_historia['parte_atual'] = 0
        if progresso_historia['capitulo_atual'] >= len(documentos):
            print("Hist√≥ria conclu√≠da!")
            return  # Retorna se a hist√≥ria estiver conclu√≠dates

# Fun√ß√£o para perguntar √† IA
def perguntar(questao):
    global progresso_historia

    try:
        # Verifica se o √≠ndice do cap√≠tulo atual √© v√°lido
        capitulo_atual = progresso_historia['capitulo_atual']
        if capitulo_atual >= len(documentos):
            raise IndexError("Cap√≠tulo atual fora do limite")

        # Verifica se o √≠ndice da parte atual √© v√°lido para o cap√≠tulo atual
        parte_atual = progresso_historia['parte_atual']
        if parte_atual >= len(documentos[capitulo_atual]['partes']):
            raise IndexError("Parte atual fora do limite")

        # Acessa a parte atual do cap√≠tulo
        parte_atual = documentos[capitulo_atual]['partes'][parte_atual]

        # Recupera o contexto para a pergunta
        contexto = retriever.get_relevant_documents(questao)
        contexto_texto = "\n".join([doc.page_content for doc in contexto])

        # Hist√≥rico de intera√ß√µes anteriores
        ultimas_interacoes = "\n".join(historico_conversa[-8:])

        # Prepara a mensagem para a IA
        mensagem = prompt.format(context=contexto_texto, historico=ultimas_interacoes, questao=questao, capitulo_atualtxt=capitulo_atual, parte_atualtxt=parte_atual)

        # Chama a IA para obter a resposta
        resposta = client.chat(model=model, messages=[{"role": "user", "content": mensagem}])

        # Avan√ßa na hist√≥ria ap√≥s a intera√ß√£o
        avancar_historia()

        return resposta['message']['content']
    
    except IndexError as e:
        print(f"Erro ao acessar a parte da hist√≥ria: {e}")
        # Garantir que a parte da hist√≥ria √© v√°lida e reiniciar se necess√°rio
        progresso_historia['capitulo_atual'] = 0
        progresso_historia['parte_atual'] = 0
        return "Erro ao acessar a hist√≥ria. Reiniciando..."

print("Ativando assistente")
print()

while True:
    perguntando = input("Voc√™: ")
    if perguntando.lower() == "sair":
        break

    resposta = perguntar(perguntando)

    # üîπ Salvar a intera√ß√£o no hist√≥rico
    historico_conversa.append(f"Jogador: {perguntando}")
    historico_conversa.append(f"Mestre: {resposta}")

    print(f"{model}: {resposta}")

# üîπ Salvar hist√≥rico em um arquivo para consultas futuras
caminho_historico = "historico_conversa.txt"
with open(caminho_historico, "w", encoding="utf-8") as arquivo:
    for linha in historico_conversa:
        arquivo.write(linha + "\n")

print("Hist√≥rico salvo em:", caminho_historico)
print("Desligando")
