from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from ollama import Client
from langchain.schema import Document
import re

# üîπ Carregar vari√°veis de ambiente
load_dotenv()

# üîπ Configurar o cliente Ollama
client = Client(host="http://localhost:11434")
model = "llama3.2"

progresso_historia = {'id_historia': 0, 'capitulo_atual': 0, 'parte_atual': 1, 'total_perguntas': 0}
total_capitulos = 0

def criar_documentos(caminho_arquivo):
    global total_capitulos

    with open(caminho_arquivo, "r", encoding="utf-8") as file:
        texto = file.read()

    padrao_capitulo = re.compile(r"(Cap√≠tulo \d+): (.*?)\n", re.DOTALL)
    padrao_parte = re.compile(r"(Parte \d+): (.*?)\n(.*?)(?=\nParte \d+:|\nCap√≠tulo \d+:|\Z)", re.DOTALL)

    documentos = []
    capitulos = list(padrao_capitulo.finditer(texto))
    total_capitulos = len(capitulos) - 1

    id_historia = -1
    for i, cap in enumerate(capitulos):
        capitulo = cap.group(1)
        titulo_capitulo = cap.group(2)
        
        inicio = cap.end()
        fim = capitulos[i + 1].start() if i + 1 < len(capitulos) else len(texto)
        trecho = texto[inicio:fim]

        partes = list(padrao_parte.finditer(trecho))
        total_partes = len(partes)

        for parte in partes:
            parte_num = int(parte.group(1).split(" ")[1])
            titulo_parte = parte.group(2)
            conteudo = parte.group(3).strip()
            id_historia += 1
            
            documento = Document(
                page_content=conteudo,
                metadata={
                    "id": id_historia,
                    "capitulo": capitulo,
                    "titulo_capitulo": titulo_capitulo,
                    "parte": parte_num,
                    "titulo_parte": titulo_parte,
                    "total_partes": total_partes
                }
            )
            documentos.append(documento)
    
    return documentos

def criar_universo(caminho_arquivo):
    with open(caminho_arquivo, "r", encoding="utf-8") as file:
        texto = file.read()
    
    # Dividir em partes menores para melhor indexa√ß√£o
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
    textos_divididos = text_splitter.split_text(texto)
    
    # Criar objetos do tipo Document
    documentos = [Document(page_content=chunk) for chunk in textos_divididos]
    return documentos

# üîπ Criar documentos a partir do arquivo
caminho_historia= "Historia.txt"
caminho_universo = "Universo.txt"

documentos = criar_documentos(caminho_historia)
docUni = criar_universo(caminho_universo)

print(documentos)

if not documentos:
    raise ValueError("Nenhum documento foi criado. Verifique a estrutura do arquivo.")

# üîπ Criar o banco de vetores FAISS
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

vectorstoreUniverse = FAISS.from_documents(docUni, embedding_model)

vectorstore = FAISS.from_documents(documentos, embedding_model)

retrieverUni = vectorstoreUniverse.as_retriever(search_type="similarity", search_kwargs={"k": 3})
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

# üîπ Hist√≥rico da conversa
historico_conversa = []

# üîπ Template de prompt
rag_template = """
Voc√™ √© um mestre de RPG de mesa conduzindo uma aventura,
Continue a hist√≥ria sem sair do Contexto,
Siga a narrativa, evite respostas longas e mantenha a continuidade l√≥gica dos eventos e da "Pergunta ou a√ß√£o:",
Continue a partir de "√öltimas a√ß√µes:",
Siga o contexto da hist√≥ria,
Deixe o jogador poder fazer as atividades que querer dentro desse universo, mesmo que nao for a hist√≥ria principal, seje criativa,
Responda com uma pergunta no final como "Oque voc√™ ir√° fazer agora?", "Qual sua proxima a√ß√£o?",
N√£o coloque falas para o jogador,
N√£o coloque falas para o mestre,
Sem op√ß√µes pr√©-definidas,
Deixe o jogador escolher as a√ß√µes que vai tomar,
Resuma sempre tudo em uma frase sempre que poss√≠vel.

Cap√≠tulo Atual: {capitulo_atualtxt}
Parte Atual: {parte_atualtxt}

Contexto: {context}
√öltimas a√ß√µes do jogador: {historico}
Pergunta ou a√ß√£o: {questao}
"""

prompt = ChatPromptTemplate.from_template(rag_template)

# üîπ Fun√ß√£o para avan√ßar na hist√≥ria
def avancar_historia(): 
    global progresso_historia
    
    print(total_capitulos)
    print(progresso_historia['capitulo_atual'])

    if progresso_historia['total_perguntas'] < 1:
        progresso_historia['total_perguntas']+=1
        return
    
    progresso_historia['total_perguntas'] = 0

    if progresso_historia['capitulo_atual'] > total_capitulos:
        print("Hist√≥ria conclu√≠da!")
        return
    
    progresso_historia['parte_atual'] += 1

    if progresso_historia['parte_atual'] > documentos[progresso_historia['id_historia']].metadata['total_partes']:
        progresso_historia['capitulo_atual'] += 1
        progresso_historia['parte_atual'] = 1

    if progresso_historia['capitulo_atual'] > total_capitulos:
        print("Hist√≥ria conclu√≠da!")
        return
    
    
    progresso_historia['id_historia'] += 1


# üîπ Fun√ß√£o para perguntar √† IA
def perguntar(questao):
    global progresso_historia
    print(progresso_historia)

    try:
        capitulo_atualSTR = documentos[progresso_historia['id_historia']].metadata['titulo_capitulo']
        parte_atualSTR = documentos[progresso_historia['id_historia']].metadata['titulo_parte']
        

        contexto = retriever.get_relevant_documents(questao)
        contexto_texto = "\n".join([doc.page_content for doc in contexto])

        print(contexto_texto)

        ultimas_interacoes = "\n".join(historico_conversa[-10:])

        mensagem = prompt.format(
            context=contexto_texto,
            historico=ultimas_interacoes,
            questao=questao,
            capitulo_atualtxt=capitulo_atualSTR,
            parte_atualtxt=parte_atualSTR
        )
        
        ##print(mensagem)
        resposta = client.chat(model=model, messages=[{"role": "user", "content": mensagem}])

        avancar_historia()
        
        return resposta['message']['content']
    except IndexError as e:
        print(f"Erro: {e}")
        return "Erro ao acessar a hist√≥ria. Reiniciando..."

print("Come√ßando Aventura:\n")
while True:
    perguntando = input("Voc√™: ")
    if perguntando.lower() == "sair":
        break
    resposta = perguntar(perguntando)
    historico_conversa.append(f"Jogador: {perguntando}")
    historico_conversa.append(f"Mestre: {resposta}")
    print(f"{model}: {resposta}")

# üîπ Salvar hist√≥rico
caminho_historico = "Historico_conversa.txt"
with open(caminho_historico, "w", encoding="utf-8") as arquivo:
    for linha in historico_conversa:
        arquivo.write(linha + "\n")

print("Hist√≥rico salvo em:", caminho_historico)
print("Desligando")