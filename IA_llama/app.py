from dotenv import load_dotenv
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from ollama import Client
from langchain.schema import Document

# üîπ Carregar vari√°veis de ambiente
load_dotenv()

# üîπ Configurar o cliente Ollama
client = Client(host="http://localhost:11434")
model = "llama3.2"

# üîπ Carregar a hist√≥ria do arquivo
historia_path = "Historia.txt"

# üîπ Carregar a hist√≥ria do arquivo
with open(historia_path, 'r', encoding='utf-8') as file:
    historia_texto = file.read()

# üîπ Fun√ß√£o para dividir a hist√≥ria em cap√≠tulos com base no formato
def dividir_em_capitulos(historia_texto):
    # L√≥gica para dividir o texto em cap√≠tulos (exemplo simples, adapta√ß√£o necess√°ria)
    capitulos = []
    # Supondo que cada cap√≠tulo seja separado por um t√≠tulo como "Cap√≠tulo X"
    for i, texto_capitulo in enumerate(historia_texto.split("Cap√≠tulo")):
        if texto_capitulo.strip():  # Ignorar partes vazias
            capitulos.append({"capitulo": f"Cap√≠tulo {i}", "texto": texto_capitulo.strip()})
    return capitulos


# Dividir a hist√≥ria em cap√≠tulos
capitulos = dividir_em_capitulos(historia_texto)

# üîπ Dividir os cap√≠tulos em partes menores
documentos_com_metadados = []

for capitulo in capitulos:
    texto = capitulo["texto"]
    capitulo_nome = capitulo["capitulo"]
    
    # Criar objetos Document para cada cap√≠tulo
    document = Document(page_content=texto, metadata={"capitulo": capitulo_nome})
    
    # Dividir o texto do cap√≠tulo em partes menores
    text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
    partes = text_splitter.split_documents([document])  # Passando a lista de Document
    
    # Adicionar metadados de cap√≠tulo e parte
    capitulo['partes'] = []  # Adiciona a chave partes para o cap√≠tulo
    for i, parte in enumerate(partes):
        parte.metadata["capitulo"] = capitulo_nome
        parte.metadata["parte"] = i + 1  # Parte 1, Parte 2, etc.
        capitulo['partes'].append(parte)  # Armazenando as partes dentro do cap√≠tulo
        documentos_com_metadados.append(parte)

# Agora voc√™ pode acessar os cap√≠tulos e suas partes da seguinte forma:
print("Cap√≠tulo Atual:", capitulos[0]['capitulo'])  # Exemplo de como acessar o cap√≠tulo
print("Partes do Cap√≠tulo 1:")
for parte in capitulos[0]['partes']:
    print(parte.metadata["parte"], ":", parte.page_content[:100])  


# üîπ Criar o banco de vetores FAISS com metadados
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = FAISS.from_documents(documentos_com_metadados, embedding_model)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

# üîπ Hist√≥rico da conversa
historico_conversa = []

# üîπ Template para manter contexto
rag_template = """
Voc√™ √© um mestre de RPG de mesa tipo D&D conduzindo uma aventura,
Continue a hist√≥ria sem sair do contexto original,
Responda apenas com uma √∫nica frase sem oferecer op√ß√µes,
Em alguns momentos voce pode fazer alguns paragrafos para ficar mais dinamico e criativo,
Siga a narrativa, evite respostas longas e mantenha a continuidade l√≥gica dos eventos,
Nunca saia do contexto da hist√≥ria,
Sempre termine a frase perguntando algo para o jogador,
Responda apenas com uma √∫nica frase sem oferecer op√ß√µes sem que posivel,
Deixe o jogador poder fazer as atividades que qerer dentro desse universo, mesmo que nao for a historia principal, seje criativa,
Responda com uma pergunta no final referente a proxima A√ß√£o do jogador.

Capitulo Atual: {capitulo_atualtxt}

Parte Atual: {parte_atualtxt}

Contexto da hist√≥ria: {context}

√öltimas a√ß√µes do jogador: {historico}

A√ß√£o do jogador agora: {questao}
"""

prompt = ChatPromptTemplate.from_template(rag_template)

progresso_historia = {'capitulo_atual': 0, 'parte_atual': 0}

# Fun√ß√£o para avan√ßar na hist√≥ria
def avancar_historia(): 
    global progresso_historia

    # Verifica se o cap√≠tulo atual √© v√°lido
    if progresso_historia['capitulo_atual'] >= len(capitulos):
        print("Hist√≥ria conclu√≠da!")
        return  # Retorna se a hist√≥ria estiver conclu√≠da

    # Verifica se a parte atual √© v√°lida para o cap√≠tulo atual

    print("Parte Atual: " , progresso_historia['parte_atual'])
    print("capitulo Atual: ",progresso_historia['capitulo_atual'])
    print("Nao sei: " , capitulos[progresso_historia['capitulo_atual']]['partes'])

    if progresso_historia['parte_atual'] >= len(capitulos[progresso_historia['capitulo_atual']]['partes']):
        # Se n√£o for v√°lida, reinicia a parte e avan√ßa para o pr√≥ximo cap√≠tulo
        progresso_historia['capitulo_atual'] += 1
        progresso_historia['parte_atual'] = 0
        if progresso_historia['capitulo_atual'] >= len(capitulos):
            print("Hist√≥ria conclu√≠da!")
            return  # Retorna se a hist√≥ria estiver conclu√≠dates

# Fun√ß√£o para perguntar √† IA
def perguntar(questao):
    global progresso_historia

    try:
        # Verifica se o √≠ndice do cap√≠tulo atual √© v√°lido
        capitulo_atual = progresso_historia['capitulo_atual']
        if capitulo_atual >= len(capitulos):
            raise IndexError("Cap√≠tulo atual fora do limite")

        # Verifica se o √≠ndice da parte atual √© v√°lido para o cap√≠tulo atual
        parte_atual = progresso_historia['parte_atual']
        if parte_atual >= len(capitulos[capitulo_atual]['partes']):
            raise IndexError("Parte atual fora do limite")

        # Acessa a parte atual do cap√≠tulo
        parte_atual = capitulos[capitulo_atual]['partes'][parte_atual]

        # Recupera o contexto para a pergunta
        contexto = retriever.get_relevant_documents(questao)
        contexto_texto = "\n".join([doc.page_content for doc in contexto])

        # Hist√≥rico de intera√ß√µes anteriores
        ultimas_interacoes = "\n".join(historico_conversa[-8:])

        # Prepara a mensagem para a IA
        mensagem = prompt.format(context=contexto_texto, historico=ultimas_interacoes, questao=questao, capitulo_atualtxt=capitulo_atual, parte_atualtxt=parte_atual)

        # Chama a IA para obter a resposta
        resposta = client.chat(model=model, messages=[{"role": "user", "content": mensagem}])

        # Avan√ßa na hist√≥ria ap√≥s a intera√ß√£o
        avancar_historia()

        return resposta['message']['content']
    
    except IndexError as e:
        print(f"Erro ao acessar a parte da hist√≥ria: {e}")
        # Garantir que a parte da hist√≥ria √© v√°lida e reiniciar se necess√°rio
        progresso_historia['capitulo_atual'] = 0
        progresso_historia['parte_atual'] = 0
        return "Erro ao acessar a hist√≥ria. Reiniciando..."

print("Ativando assistente")
print()

while True:
    perguntando = input("Voc√™: ")
    if perguntando.lower() == "sair":
        break

    resposta = perguntar(perguntando)

    # üîπ Salvar a intera√ß√£o no hist√≥rico
    historico_conversa.append(f"Jogador: {perguntando}")
    historico_conversa.append(f"Mestre: {resposta}")

    print(f"{model}: {resposta}")

# üîπ Salvar hist√≥rico em um arquivo para consultas futuras
caminho_historico = "historico_conversa.txt"
with open(caminho_historico, "w", encoding="utf-8") as arquivo:
    for linha in historico_conversa:
        arquivo.write(linha + "\n")

print("Hist√≥rico salvo em:", caminho_historico)
print("Desligando")
