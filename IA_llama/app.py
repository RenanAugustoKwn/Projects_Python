from dotenv import load_dotenv
from langchain.text_splitter import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from ollama import Client
from langchain.schema import Document
import re

# ðŸ”¹ Carregar variÃ¡veis de ambiente
load_dotenv()

# ðŸ”¹ Configurar o cliente Ollama
client = Client(host="http://localhost:11434")
model = "llama3.2"

progresso_historia = {'id_historia': 0, 'capitulo_atual': 0, 'parte_atual': 0}
total_capitulos = 0

def criar_documentos(caminho_arquivo):
    global total_capitulos

    with open(caminho_arquivo, "r", encoding="utf-8") as file:
        texto = file.read()

    padrao_capitulo = re.compile(r"(CapÃ­tulo \d+): (.*?)\n", re.DOTALL)
    padrao_parte = re.compile(r"(Parte \d+): (.*?)\n(.*?)(?=\nParte \d+:|\nCapÃ­tulo \d+:|\Z)", re.DOTALL)

    documentos = []
    capitulos = list(padrao_capitulo.finditer(texto))
    total_capitulos = len(capitulos)

    id_historia = 0
    for i, cap in enumerate(capitulos):
        capitulo = cap.group(1)
        titulo_capitulo = cap.group(2)
        
        inicio = cap.end()
        fim = capitulos[i + 1].start() if i + 1 < len(capitulos) else len(texto)
        trecho = texto[inicio:fim]

        partes = list(padrao_parte.finditer(trecho))
        total_partes = len(partes)

        for parte in partes:
            parte_num = int(parte.group(1).split(" ")[1])
            titulo_parte = parte.group(2)
            conteudo = parte.group(3).strip()
            id_historia += 1
            
            documento = Document(
                page_content=conteudo,
                metadata={
                    "id": id_historia,
                    "capitulo": capitulo,
                    "titulo_capitulo": titulo_capitulo,
                    "parte": parte_num,
                    "titulo_parte": titulo_parte,
                    "total_partes": total_partes
                }
            )
            documentos.append(documento)
    
    return documentos

# ðŸ”¹ Criar documentos a partir do arquivo
caminho_arquivo = "historia.txt"
documentos = criar_documentos(caminho_arquivo)

# Exibir os resultados
print(documentos)

if not documentos:
    raise ValueError("Nenhum documento foi criado. Verifique a estrutura do arquivo.")

# ðŸ”¹ Criar o banco de vetores FAISS
embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
vectorstore = FAISS.from_documents(documentos, embedding_model)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

# ðŸ”¹ HistÃ³rico da conversa
historico_conversa = []

# ðŸ”¹ Template de prompt
rag_template = """
VocÃª Ã© um mestre de RPG de mesa tipo D&D conduzindo uma aventura,
Continue a histÃ³ria sem sair do contexto original,
Sempre termine com uma pergunta sobre a prÃ³xima aÃ§Ã£o do jogador.
Responda apenas com uma Ãºnica frase sem oferecer opÃ§Ãµes,
Em alguns momentos voce pode fazer alguns paragrafos para ficar mais dinamico e criativo,
Siga a narrativa, evite respostas longas e mantenha a continuidade lÃ³gica dos eventos,
Nunca saia do contexto da histÃ³ria,
Sempre termine a frase perguntando algo para o jogador,
Responda apenas com uma Ãºnica frase sem oferecer opÃ§Ãµes sem que posivel,
Deixe o jogador poder fazer as atividades que qerer dentro desse universo, mesmo que nao for a historia principal, seje criativa,
Responda com uma pergunta no final referente a proxima AÃ§Ã£o do jogador.

CapÃ­tulo Atual: {capitulo_atualtxt}
Parte Atual: {parte_atualtxt}

Contexto da histÃ³ria: {context}
Ãšltimas aÃ§Ãµes do jogador: {historico}
AÃ§Ã£o do jogador agora: {questao}
"""

prompt = ChatPromptTemplate.from_template(rag_template)

# ðŸ”¹ FunÃ§Ã£o para avanÃ§ar na histÃ³ria
def avancar_historia(): 
    global progresso_historia

    if progresso_historia['capitulo_atual'] >= total_capitulos:
        print("HistÃ³ria concluÃ­da!")
        return
    
    progresso_historia['parte_atual'] += 1
    if progresso_historia['parte_atual'] >= documentos[progresso_historia['id_historia']].metadata['total_partes']:
        progresso_historia['capitulo_atual'] += 1
        progresso_historia['parte_atual'] = 0

    if progresso_historia['capitulo_atual'] >= total_capitulos:
        print("HistÃ³ria concluÃ­da!")

# ðŸ”¹ FunÃ§Ã£o para perguntar Ã  IA
def perguntar(questao):
    global progresso_historia

    try:
        capitulo_atualSTR = documentos[progresso_historia['id_historia']].metadata['titulo_capitulo']
        parte_atualSTR = documentos[progresso_historia['id_historia']].metadata['titulo_parte']
        
        contexto = retriever.get_relevant_documents(questao)
        contexto_texto = "\n".join([doc.page_content for doc in contexto])

        ultimas_interacoes = "\n".join(historico_conversa[-8:])

        mensagem = prompt.format(
            context=contexto_texto,
            historico=ultimas_interacoes,
            questao=questao,
            capitulo_atualtxt=capitulo_atualSTR,
            parte_atualtxt=parte_atualSTR
        )
        
        print(mensagem)
        resposta = client.chat(model=model, messages=[{"role": "user", "content": mensagem}])
        avancar_historia()
        
        return resposta['message']['content']
    except IndexError as e:
        print(f"Erro: {e}")
        return "Erro ao acessar a histÃ³ria. Reiniciando..."

print("Ativando assistente\n")
while True:
    perguntando = input("VocÃª: ")
    if perguntando.lower() == "sair":
        break
    resposta = perguntar(perguntando)
    historico_conversa.append(f"Jogador: {perguntando}")
    historico_conversa.append(f"Mestre: {resposta}")
    print(f"{model}: {resposta}")

# ðŸ”¹ Salvar histÃ³rico
caminho_historico = "historico_conversa.txt"
with open(caminho_historico, "w", encoding="utf-8") as arquivo:
    for linha in historico_conversa:
        arquivo.write(linha + "\n")

print("HistÃ³rico salvo em:", caminho_historico)
print("Desligando")